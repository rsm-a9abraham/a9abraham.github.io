---
title: "A Replication of Karlan and List (2007)"
author: "Allen Abraham"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).


This project seeks to replicate their results. Expand this part


## Data

```{python}
#| message: false
#| echo: true

import pandas as pd

data = pd.read_stata('data/karlan_list_2007.dta')
data.to_csv('data/karlan_list_2007.csv', index=False)
data

```


### Description of Data

The data set contains 50,083 observations and 51 variables. The key variables are as follows:

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

_todo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._

##### Months Since Last Donation (mrm2)

Using the variable `mrm2`, I test the balance of the treatment and control groups. I first calculate the difference in means between the treatment and control groups and then use both a t-test and linear regression to test whether this difference is statistically significant at the 95% confidence level.

```{python}
#| message: false
#| echo: true

#first, let's test the balance of the treatment and control groups on the variable mrm2 using a t-test

#average months since last donation for the treatment group
treatment_mrm2 = data[data['treatment'] == 1]['mrm2'].mean()

#average months since last donation for the control group
control_mrm2 = data[data['control'] == 1]['mrm2'].mean()

#standard deviation of months since last donation for the treatment group
treatment_mrm2_sd = data[data['treatment'] == 1]['mrm2'].std()

#standard deviation of months since last donation for the control group
control_mrm2_sd = data[data['control'] == 1]['mrm2'].std()

#number of observations in the treatment group
n_treatment = data['treatment'].sum()

#number of observations in the control group
n_control = data['control'].sum()

#difference in means between the treatment and control groups
diff_mrm2 = treatment_mrm2 - control_mrm2

print("difference in means between control and treatment group for mrm2: ", diff_mrm2)

#t-statistic
t_stat_mrm2 = (treatment_mrm2 - control_mrm2) / (((treatment_mrm2_sd**2 / n_treatment) + (control_mrm2_sd**2 / n_control))**0.5)

print("t-statistic for mrm2: ", t_stat_mrm2)


#convert the t-statistic to a p-value
from scipy.stats import t

p_value_mrm2 = t.sf(t_stat_mrm2, n_treatment + n_control - 2)*2

print("p-value for mrm2: ", p_value_mrm2)
```

```{python}
#| message: false
#| echo: true

#now let's test the balance of the treatment and control groups on the variable mrm2 using a linear regression

import statsmodels.api as sm

model = sm.OLS.from_formula('mrm2 ~ treatment', data=data)
results = model.fit()

#extract the coefficient and p_value on the treatment variable
coef = results.params['treatment']
t_stat = results.tvalues['treatment']
p_value = results.pvalues['treatment']

print("coefficient for mrm2: ", coef)
print("t-statistic for mrm2: ", t_stat)
print("p-value for mrm2: ", p_value)


```

Using both the t-test and linear regression, the p-value for the difference in means between the treatment and control groups for the variable `mrm2` is 0.905. This means that if the null hypothesis is true, we would expect to see a difference in means as extreme as the one we observed in 0.905% of cases. Therefore, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different at the 95% confidence level. This suggests that the randomization was successful and the treatment and control groups are balanced with respect to the variable `mrm2`.

##### Highest Previous Contribution (hpa)

Next, I test the balance of the treatment and control groups on the variable `hpa` using both a t-test and linear regression.

```{python}
#| message: false
#| echo: true

#average highest previous contribution for the treatment group
treatment_hpa = data[data['treatment'] == 1]['hpa'].mean()

#average highest previous contribution for the control group
control_hpa = data[data['control'] == 1]['hpa'].mean()

#standard deviation of highest previous contribution for the treatment group
treatment_hpa_sd = data[data['treatment'] == 1]['hpa'].std()

#standard deviation of highest previous contribution for the control group
control_hpa_sd = data[data['control'] == 1]['hpa'].std()

#number of observations in the treatment group
n_treatment = data['treatment'].sum()

#number of observations in the control group
n_control = data['control'].sum()

#difference in means between the treatment and control groups
diff_hpa = treatment_hpa - control_hpa

print("difference in means between control and treatment group for hpa: ", diff_hpa)

#t-statistic
t_stat_hpa = (treatment_hpa - control_hpa) / (((treatment_hpa_sd**2 / n_treatment) + (control_hpa_sd**2 / n_control))**0.5)

print("t-statistic for hpa: ", t_stat_hpa)

#convert the t-statistic to a p-value
p_value_hpa = t.sf(t_stat_hpa, n_treatment + n_control - 2)*2

print("p-value for hpa: ", p_value_hpa)

```

```{python}
#| message: false
#| echo: true

#now let's test the balance of the treatment and control groups on the variable hpa using a linear regression

model = sm.OLS.from_formula('hpa ~ treatment', data=data)
results = model.fit()

#extract the coefficient and p_value on the treatment variable
coef = results.params['treatment']
t_stat = results.tvalues['treatment']
p_value = results.pvalues['treatment']

print("coefficient for hpa: ", coef)
print("t-statistic for hpa: ", t_stat)
print("p-value for hpa: ", p_value)

```

Using both the t-test and linear regression, the p-value for the difference in means between the treatment and control groups for the variable `hpa` is 0.34. This means that if the null hypothesis is true, we would expect to see a difference in means as extreme as the one we observed in 34% of cases. Therefore, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different at the 95% confidence level. This suggests that the randomization was successful and the treatment and control groups are balanced with respect to the variable `hpa`.


### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

_todo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control._

```{python}
#| message: false
#| echo: true

import matplotlib.pyplot as plt

#proportion of people who donated in the treatment group
prop_treatment = data[data['treatment'] == 1]['gave'].mean()

#proportion of people who donated in the control group
prop_control = data[data['control'] == 1]['gave'].mean()

plt.bar(['Treatment', 'Control'], [prop_treatment, prop_control])
plt.ylabel('Proportion of People Who Donated')
plt.title('Proportion of People Who Donated by Treatment and Control Group')
plt.show()


```

_todo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)_

```{python}
#| message: false
#| echo: true

#t-test between treatment and control groups on the binary outcome of whether any charitable donation was made
from scipy.stats import ttest_ind

treatment_gave = data[data['treatment'] == 1]['gave']
control_gave = data[data['control'] == 1]['gave']

diff = treatment_gave.mean() - control_gave.mean()

t_stat, p_value = ttest_ind(treatment_gave, control_gave)

print("difference in response rates between control and treatment: ", diff)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)
```

```{python}
#| message: false
#| echo: true

#bivariate linear regression that demonstrates the same finding
model = sm.OLS(data['gave'], sm.add_constant(data['treatment']))
results = model.fit()

#extract the coefficient and p_value on the treatment variable
coef = results.params['treatment']
t_stat = results.tvalues['treatment']
p_value = results.pvalues['treatment']

print("coefficient: ", coef)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)

```

The t-test and linear regression both show that the difference in response rates between the treatment and control groups is statistically significant at the 95% confidence level. This suggests that the treatment of receiving a matched donation led to an increased likelihood of making a charitable donation. This finding is consistent with the results reported in Table 2a Panel A of the paper and their interpretation that the treatment effect is statistically significant.

_todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper._

```{python}
#| message: false
#| echo: true

model = sm.Probit(data['gave'], sm.add_constant(data['treatment']))
results = model.fit()



coef = results.params['treatment']
z_stat = results.tvalues['treatment']
p_value = results.pvalues['treatment']

print("coefficient", coef)
print("z-statistic: ", z_stat)
print("p-value: ", p_value)

#model summary
results.summary()
```

The probit regression confirms that the coefficient on the treatment variable is statistically significant at the 95% confidence level. This result is consistent with the findings reported in Table 3 column 1 of the paper, which suggests that the treatment of receiving a matched donation led to an increased likelihood of making a charitable donation.


### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

_todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the "figures suggest" comment the authors make on page 8?

```{python}
#| message: false
#| echo: true

#t-test between 1:1 and 2:1 match ratios on the binary outcome of whether any charitable donation was made
treatment_gave_1 = data[data['treatment'] == 1]['gave'][data['ratio'] == 1]
treatment_gave_2 = data[data['treatment'] == 1]['gave'][data['ratio'] == 2]

diff = treatment_gave_2.mean() - treatment_gave_1.mean()

t_stat, p_value = ttest_ind(treatment_gave_2, treatment_gave_1)

print("difference in response rates between 1:1 and 2:1 match ratios: ", diff)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)

```

```{python}
#| message: false
#| echo: true

#t-test between 2:1 and 3:1 match ratios on the binary outcome of whether any charitable donation was made
treatment_gave_2 = data[data['treatment'] == 1]['gave'][data['ratio'] == 2]
treatment_gave_3 = data[data['treatment'] == 1]['gave'][data['ratio'] == 3]

diff = treatment_gave_3.mean() - treatment_gave_2.mean()

t_stat, p_value = ttest_ind(treatment_gave_3, treatment_gave_2)

print("difference in response rates between 2:1 and 3:1 match ratios: ", diff)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)

```

```{python}
#| message: false
#| echo: true

#t-test between 1:1 and 3:1 match ratios on the binary outcome of whether any charitable donation was made
treatment_gave_1 = data[data['treatment'] == 1]['gave'][data['ratio'] == 1]
treatment_gave_3 = data[data['treatment'] == 1]['gave'][data['ratio'] == 3]

diff = treatment_gave_3.mean() - treatment_gave_1.mean()

t_stat, p_value = ttest_ind(treatment_gave_3, treatment_gave_1)

print("difference in response rates between 1:1 and 3:1 match ratios: ", diff)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)

```

The t-tests and the resulting p-values show that the difference in response rates between the 1:1 and 2:1 match ratios, the 2:1 and 3:1 match ratios, and the 1:1 and 3:1 match ratios are all statistically insignificant at the 95% confidence level. This suggests that the size of the matched donation does not have a statistically significant effect on the likelihood of making a charitable donation. This finding is consistent with the  comment the authors make on page 8, which suggests that the figures do not suggest a clear pattern of increasing response rates with larger match ratios.




_todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision._


```{python}
#| message: false
#| echo: true

# Create a new variable 'ratio1' that is equal to 1 if the match ratio is 1:1 and 0 otherwise
data['ratio1'] = (data['ratio'] == 1).astype(int)

model = sm.Probit.from_formula('gave ~ ratio1 + ratio2 + ratio3', data=data)
results = model.fit()

results.summary()
```

The regression results show that the coefficients on the `ratio` variable are statistically insignificant at the 90% confidence level. Ratio1 (1:1) has a coefficient of -0.0029 with p-value of .097, ratio2 (2:1) has a coefficient of -0.0048 with p-value of .006, and ratio3 (3:1) has a coefficient of -0.0049 with p-value of .005. This suggests that the 

_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_


### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

_todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?_

```{python}
#| message: false
#| echo: true

#t-test between treatment and control groups on the donation amount
treatment_amount = data[data['treatment'] == 1]['amount']
control_amount = data[data['control'] == 1]['amount']

diff = treatment_amount.mean() - control_amount.mean()

t_stat, p_value = ttest_ind(treatment_amount, control_amount)

print("difference in donation amounts between control and treatment: ", diff)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)
```

```{python}
#| message: false
#| echo: true

#bivariate linear regression of the donation amount on the treatment status
model = sm.OLS.from_formula('amount ~ treatment', data=data)
results = model.fit()

#extract the coefficient and p_value on the treatment variable
coef = results.params['treatment']
t_stat = results.tvalues['treatment']
p_value = results.pvalues['treatment']

print("coefficient: ", coef)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)

```

The p-value (.063) for the difference in donation amounts between the treatment and control groups is statistically significant at the 90% confidence level. This suggests that the treatment of receiving a matched donation led to a higher average donation amount. 

_todo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients -- what did we learn? Does the treatment coefficient have a causal interpretation?_ 

```{python}
#| message: false
#| echo: true

#limit the data to just people who made a donation
donated_data = data[data['gave'] == 1]

#t-test between treatment and control groups on the donation amount among people who donated
treatment_amount = donated_data[donated_data['treatment'] == 1]['amount']
control_amount = donated_data[donated_data['control'] == 1]['amount']

diff = treatment_amount.mean() - control_amount.mean()

t_stat, p_value = ttest_ind(treatment_amount, control_amount)

print("difference in donation amounts between control and treatment among people who donated: ", diff)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)
```

```{python}
#| message: false
#| echo: true

#bivariate linear regression of the donation amount on the treatment status among people who donated
model = sm.OLS.from_formula('amount ~ treatment', data=donated_data)
results = model.fit()

#extract the coefficient and p_value on the treatment variable
coef = results.params['treatment']
t_stat = results.tvalues['treatment']
p_value = results.pvalues['treatment']

print("coefficient: ", coef)
print("t-statistic: ", t_stat)
print("p-value: ", p_value)

```

Among all the people who donated, those who did not recieve the treatment of matching donation actually donated more on average. However, the p-value (.56) suggests that this difference is not statistically significant. So we cannot conclude that the treatment of receiving a matched donation led to a higher average donation amount among people who donated.

_todo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.

```{python}
#| message: false
#| echo: true


#plot histogram of donation amounts for the treatment group among people who donated
plt.hist(donated_data[donated_data['treatment'] == 1]['amount'], bins=20, color='skyblue', edgecolor='black')
plt.axvline(donated_data[donated_data['treatment'] == 1]['amount'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Donation Amount')
plt.title('Distribution of Donation Amounts Among People Who Donated (Treatment)')
plt.xlabel('Donation Amount')
plt.ylabel('Frequency')
plt.legend()
plt.show()

#plot histogram of donation amounts for the control group among people who donated
plt.hist(donated_data[donated_data['control'] == 1]['amount'], bins=20, color='skyblue', edgecolor='black')
plt.axvline(donated_data[donated_data['control'] == 1]['amount'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Donation Amount')
plt.title('Distribution of Donation Amounts Among People Who Donated (Control)')
plt.xlabel('Donation Amount')
plt.ylabel('Frequency')
plt.legend()
plt.show()


```
## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

_to do:  Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means._

```{python}
#| message: false
#| echo: true

import numpy as np
import matplotlib.pyplot as plt

# Separate the treatment and control groups for the "amount" variable
treatment_amount = data[data['treatment'] == 1]['amount']
control_amount = data[data['treatment'] == 0]['amount']

# Calculate the true difference in means
true_diff = treatment_amount.mean() - control_amount.mean()

np.random.seed(0)

# Simulate 100,000 draws from the control distribution
simulated_control_draws = np.random.choice(control_amount, 10000, replace=False)
simulated_treatment_draws = np.random.choice(treatment_amount, 10000, replace=False)

# Calculate the vector of 10,000 differences
differences = simulated_treatment_draws - simulated_control_draws

# Calculate the cumulative average of the vector of differences
cumulative_average_differences = np.cumsum(differences) / np.arange(1, 10001)


plt.figure(figsize=(10, 6))
plt.plot(cumulative_average_differences, color='red')
plt.axhline(y=true_diff, color='black', linestyle='--', label='True Difference in Means')
plt.xlabel('Number of Draws')
plt.ylabel('Cumulative Average Difference')
plt.title('Cumulative Average of Differences in "Amount" Between Treatment and Control')
plt.legend()
plt.grid(True)
plt.show()




```

The plot shows the cumulative average of the differences in "amount" between the treatment and control groups as the number of draws increases. The cumulative average approaches the true difference in means as the number of draws increases, which demonstrates the Law of Large Numbers. This means that the more draws we take, the closer the average difference in "amount" between the treatment and control groups will be to the true difference in means.

### Central Limit Theorem

_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_

```{python}
#| message: false
#| echo: true

import numpy as np
import matplotlib.pyplot as plt

treatment_amount = data[data['treatment'] == 1]['amount']
control_amount = data[data['treatment'] == 0]['amount']

true_diff =  treatment_amount.mean()-control_amount.mean()
print('True Difference in mean of "amount" between Control and Treatment:', true_diff)

# Simulate 1000 draws of 50, 200, 500, and 1000 from both the control and treatment distributions
sample_sizes = [50, 200, 500, 1000]
num_simulations = 1000

np.random.seed(0)

for sample_size in sample_sizes:
    sample_diffs = []
    for _ in range(num_simulations):
        simulated_control_draws = np.random.choice(control_amount, sample_size, replace=False)
        simulated_treatment_draws = np.random.choice(treatment_amount, sample_size, replace=False)
        sample_diffs.append(simulated_treatment_draws.mean() - simulated_control_draws.mean())

    plt.hist(sample_diffs, bins=20, color='skyblue', edgecolor='black')
    plt.axvline(x=true_diff, color='red', linestyle='--', label='True Difference in Means')
    plt.xlabel('Sample Difference in Means')
    plt.ylabel('Frequency')
    plt.title(f'Histogram of Sample Differences in Means (Sample Size = {sample_size})')
    plt.legend()
    plt.show()
```

The above histogram illustrates the Central Limit Theorem. As the sample size increases, the sampling distribution of the average of differences between the mean becomes normal. The zero is in the middle of the distribution because the true difference in mean of the `amount` variable between the control and treament is close to zero and the difference is not significant as proven earlier. 

