[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Allen’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Allen Abraham",
    "section": "",
    "text": "Marketing Analytics Website"
  },
  {
    "objectID": "projects/project 1/index.html",
    "href": "projects/project 1/index.html",
    "title": "Making a quarto page",
    "section": "",
    "text": "import pandas as pd\nhi how are you"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Poisson Regression Examples\n\n\n\n\n\n\nAllen Abraham\n\n\nMay 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMaking a quarto page\n\n\n\n\n\n\nAllen Abraham\n\n\nMay 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nAllen Abraham\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project 1/index.html#sub-section",
    "href": "projects/project 1/index.html#sub-section",
    "title": "Making a quarto page",
    "section": "Sub-section",
    "text": "Sub-section\n\nHeader\n\nsome\nnumbers\nin\na\nlist\n\ntext can be bold, or italics, or strikethrough\nMy website is http://www.google.com or here"
  },
  {
    "objectID": "projects/Trial Assignment/index.html",
    "href": "projects/Trial Assignment/index.html",
    "title": "Making a quarto page",
    "section": "",
    "text": "import pandas as pd\nhi how are you"
  },
  {
    "objectID": "projects/Trial Assignment/index.html#sub-section",
    "href": "projects/Trial Assignment/index.html#sub-section",
    "title": "Making a quarto page",
    "section": "Sub-section",
    "text": "Sub-section\n\nHeader\n\nsome\nnumbers\nin\na\nlist\n\ntext can be bold, or italics, or strikethrough\nMy website is http://www.google.com or here"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Allen Abraham",
    "section": "",
    "text": "Marketing Analytics Website"
  },
  {
    "objectID": "projects/Assignment 1/hw1_questions.html",
    "href": "projects/Assignment 1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results utilizing various forms of hypothesis testing, to include t-test, linear regression, and probit regression."
  },
  {
    "objectID": "projects/Assignment 1/hw1_questions.html#introduction",
    "href": "projects/Assignment 1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results utilizing various forms of hypothesis testing, to include t-test, linear regression, and probit regression."
  },
  {
    "objectID": "projects/Assignment 1/hw1_questions.html#data",
    "href": "projects/Assignment 1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nimport pandas as pd\n\ndata = pd.read_stata('data/karlan_list_2007.dta')\ndata.to_csv('data/karlan_list_2007.csv', index=False)\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\nDescription of Data\nThe data set contains 50,083 observations and 51 variables. The key variables are as follows:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nMonths Since Last Donation (mrm2)\nUsing the variable mrm2, I test the balance of the treatment and control groups. I first calculate the difference in means between the treatment and control groups and then use both a t-test and linear regression to test whether this difference is statistically significant at the 95% confidence level.\n\n#first, let's test the balance of the treatment and control groups on the variable mrm2 using a t-test\n\n#average months since last donation for the treatment group\ntreatment_mrm2 = data[data['treatment'] == 1]['mrm2'].mean()\n\n#average months since last donation for the control group\ncontrol_mrm2 = data[data['control'] == 1]['mrm2'].mean()\n\n#standard deviation of months since last donation for the treatment group\ntreatment_mrm2_sd = data[data['treatment'] == 1]['mrm2'].std()\n\n#standard deviation of months since last donation for the control group\ncontrol_mrm2_sd = data[data['control'] == 1]['mrm2'].std()\n\n#number of observations in the treatment group\nn_treatment = data['treatment'].sum()\n\n#number of observations in the control group\nn_control = data['control'].sum()\n\n#difference in means between the treatment and control groups\ndiff_mrm2 = treatment_mrm2 - control_mrm2\n\nprint(\"difference in means between control and treatment group for mrm2: \", diff_mrm2)\n\n#t-statistic\nt_stat_mrm2 = (treatment_mrm2 - control_mrm2) / (((treatment_mrm2_sd**2 / n_treatment) + (control_mrm2_sd**2 / n_control))**0.5)\n\nprint(\"t-statistic for mrm2: \", t_stat_mrm2)\n\n\n#convert the t-statistic to a p-value\nfrom scipy.stats import t\n\np_value_mrm2 = t.sf(t_stat_mrm2, n_treatment + n_control - 2)*2\n\nprint(\"p-value for mrm2: \", p_value_mrm2)\n\ndifference in means between control and treatment group for mrm2:  0.013685851546783923\nt-statistic for mrm2:  0.11953214935937886\np-value for mrm2:  0.9048542505673348\n\n\n\n#now let's test the balance of the treatment and control groups on the variable mrm2 using a linear regression\n\nimport statsmodels.api as sm\n\nmodel = sm.OLS.from_formula('mrm2 ~ treatment', data=data)\nresults = model.fit()\n\n#extract the coefficient and p_value on the treatment variable\ncoef = results.params['treatment']\nt_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient for mrm2: \", coef)\nprint(\"t-statistic for mrm2: \", t_stat)\nprint(\"p-value for mrm2: \", p_value)\n\ncoefficient for mrm2:  0.013685851546783642\nt-statistic for mrm2:  0.11949210581591664\np-value for mrm2:  0.9048859731777759\n\n\nUsing both the t-test and linear regression, the p-value for the difference in means between the treatment and control groups for the variable mrm2 is 0.905. This means that if the null hypothesis is true, we would expect to see a difference in means as extreme as the one we observed in 90.5% of cases. Therefore, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different at the 95% confidence level. This suggests that the randomization was successful and the treatment and control groups are balanced with respect to the variable mrm2. The difference in means and linear regression coefficient of .014 matches the difference between the treatment and control group for “number of months since last donation” in Table 1 of the research paper. This table is provided to show that the treatment and control group is balanced and sampling bias should be low since the treatment and control group were picked randomly.\n\n\nHighest Previous Contribution (hpa)\nNext, I test the balance of the treatment and control groups on the variable hpa using both a t-test and linear regression.\n\n#average highest previous contribution for the treatment group\ntreatment_hpa = data[data['treatment'] == 1]['hpa'].mean()\n\n#average highest previous contribution for the control group\ncontrol_hpa = data[data['control'] == 1]['hpa'].mean()\n\n#standard deviation of highest previous contribution for the treatment group\ntreatment_hpa_sd = data[data['treatment'] == 1]['hpa'].std()\n\n#standard deviation of highest previous contribution for the control group\ncontrol_hpa_sd = data[data['control'] == 1]['hpa'].std()\n\n#number of observations in the treatment group\nn_treatment = data['treatment'].sum()\n\n#number of observations in the control group\nn_control = data['control'].sum()\n\n#difference in means between the treatment and control groups\ndiff_hpa = treatment_hpa - control_hpa\n\nprint(\"difference in means between control and treatment group for hpa: \", diff_hpa)\n\n#t-statistic\nt_stat_hpa = (treatment_hpa - control_hpa) / (((treatment_hpa_sd**2 / n_treatment) + (control_hpa_sd**2 / n_control))**0.5)\n\nprint(\"t-statistic for hpa: \", t_stat_hpa)\n\n#convert the t-statistic to a p-value\np_value_hpa = t.sf(t_stat_hpa, n_treatment + n_control - 2)*2\n\nprint(\"p-value for hpa: \", p_value_hpa)\n\ndifference in means between control and treatment group for hpa:  0.6370735\nt-statistic for hpa:  0.9703896843548359\np-value for hpa:  0.3318569750696071\n\n\n\n#now let's test the balance of the treatment and control groups on the variable hpa using a linear regression\n\nmodel = sm.OLS.from_formula('hpa ~ treatment', data=data)\nresults = model.fit()\n\n#extract the coefficient and p_value on the treatment variable\ncoef = results.params['treatment']\nt_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient for hpa: \", coef)\nprint(\"t-statistic for hpa: \", t_stat)\nprint(\"p-value for hpa: \", p_value)\n\ncoefficient for hpa:  0.6370752896561251\nt-statistic for hpa:  0.9441476332014095\np-value for hpa:  0.3450987657186726\n\n\nUsing both the t-test and linear regression, the p-value for the difference in means between the treatment and control groups for the variable hpa is 0.34. This means that if the null hypothesis is true, we would expect to see a difference in means as extreme as the one we observed in 34% of cases. Therefore, we fail to reject the null hypothesis that the treatment and control groups are similar at the 95% confidence level.\nThis suggests that the randomization was successful and the treatment and control groups are balanced with respect to the variable hpa. The difference in means and linear regression coefficient of 0.637 matches the difference between the treatment and control group for “highest previous contribution” in Table 1 of the research paper.\n\n\nNumber of Prior Donations (freq)\nFinally, I test the balance of the treatment and control groups on the variable freq using both a t-test and linear regression.\n\n#average number of prior donations for the treatment group\ntreatment_freq = data[data['treatment'] == 1]['freq'].mean()\n\n#average number of prior donations for the control group\ncontrol_freq = data[data['control'] == 1]['freq'].mean()\n\n#standard deviation of number of prior donations for the treatment group\ntreatment_freq_sd = data[data['treatment'] == 1]['freq'].std()\n\n#standard deviation of number of prior donations for the control group\ncontrol_freq_sd = data[data['control'] == 1]['freq'].std()\n\n#number of observations in the treatment group\nn_treatment = data['treatment'].sum()\n\n#number of observations in the control group\nn_control = data['control'].sum()\n\n#difference in means between the treatment and control groups\ndiff_freq = treatment_freq - control_freq\n\nprint(\"difference in means between control and treatment group for freq: \", diff_freq)\n\n#t-statistic\nt_stat_freq = (treatment_freq - control_freq) / (((treatment_freq_sd**2 / n_treatment) + (control_freq_sd**2 / n_control))**0.5)\n\nprint(\"t-statistic for freq: \", t_stat_freq)\n\n\n# convert the t-statistic to a p-value using cdf instead of sf\np_value_freq =  t.cdf(t_stat_freq, n_treatment + n_control - 2)*2\n\nprint(\"p-value for freq: \", p_value_freq)\n\ndifference in means between control and treatment group for freq:  -0.011978725875380292\nt-statistic for freq:  -0.11084502380904246\np-value for freq:  0.9117396856546793\n\n\n\n#now let's test the balance of the treatment and control groups on the variable freq using a linear regression\n\nmodel = sm.OLS.from_formula('freq ~ treatment', data=data)\nresults = model.fit()\n\n#extract the coefficient and p_value on the treatment variable\ncoef = results.params['treatment']\nt_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient for freq: \", coef)\nprint(\"t-statistic for freq: \", t_stat)\nprint(\"p-value for freq: \", p_value)\n\ncoefficient for freq:  -0.011978725875379325\nt-statistic for freq:  -0.11089297035979087\np-value for freq:  0.9117016644344662\n\n\nUsing both the t-test and linear regression, the p-value for the difference in means between the treatment and control groups for the variable freq is 0.91. This means that if the null hypothesis is true, we would expect to see a difference in means as extreme as the one we observed in 91% of cases. Therefore, we fail to reject the null hypothesis that states that the treatment and control groups are similar at the 95% confidence level.\nThis suggests that the randomization was successful and the treatment and control groups are balanced with respect to the variable freq. The difference in means and linear regression coefficient of -0.012 matches the difference between the treatment and control group for “number of prior donations” in Table 1 of the research paper.\n\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n#proportion of people who donated in the treatment group\nprop_treatment = data[data['treatment'] == 1]['gave'].mean()\n\n#proportion of people who donated in the control group\nprop_control = data[data['control'] == 1]['gave'].mean()\n\nplt.bar(['Treatment', 'Control'], [prop_treatment, prop_control])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of People Who Donated by Treatment and Control Group')\nplt.show()\n\n\n\n\n\n\n\n\n\n#t-test between treatment and control groups on the binary outcome of whether any charitable donation was made\nfrom scipy.stats import ttest_ind\n\ntreatment_gave = data[data['treatment'] == 1]['gave']\ncontrol_gave = data[data['control'] == 1]['gave']\n\ndiff = treatment_gave.mean() - control_gave.mean()\n\nt_stat, p_value = ttest_ind(treatment_gave, control_gave)\n\nprint(\"difference in response rates between control and treatment: \", diff)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ndifference in response rates between control and treatment:  0.00418035451294875\nt-statistic:  3.101361000543946\np-value:  0.0019274025949016982\n\n\n\n#bivariate linear regression that demonstrates the same finding\nmodel = sm.OLS(data['gave'], sm.add_constant(data['treatment']))\nresults = model.fit()\n\n#extract the coefficient and p_value on the treatment variable\ncoef = results.params['treatment']\nt_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient: \", coef)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ncoefficient:  0.004180354512948743\nt-statistic:  3.101361000543942\np-value:  0.0019274025949017242\n\n\nThe p-value of .002 for both the t-test and linear regression indicates that the difference in response rates between the treatment and control groups is statistically significant at the 95% confidence level. If the null hypothesis of the response rate being the same for both control and treatment group is true, we would expect to see a difference in response rates as extreme as the one we observed in only 0.2% of cases. Therefore, we reject the null hypothesis that the treatment and control groups are the same with respect to the likelihood of making a charitable donation.\nThis suggests that the treatment of receiving a matched donation led to an increased likelihood of making a charitable donation. This finding is consistent with the results reported in Table 2a Panel A of the paper and their interpretation that the treatment effect is statistically significant.\n\nmodel = sm.Probit(data['gave'], sm.add_constant(data['treatment']))\nresults = model.fit()\n\n\n\ncoef = results.params['treatment']\nz_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient\", coef)\nprint(\"z-statistic: \", z_stat)\nprint(\"p-value: \", p_value)\n\n#model summary\nresults.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\ncoefficient 0.08678462244745848\nz-statistic:  3.112930073795023\np-value:  0.0018523990147783487\n\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nMon, 29 Apr 2024\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n14:53:01\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\nThe probit regression confirms that the treatment effect is statistically significant at the 95% confidence level. Although the coefficient is different from the linear regression, the p-value of .002 is consistent with the t-test and linear regression results.\nAlthough Table 3 (Primary Regression Results) in the paper states that it is reporting coefficients of the probit regression, I was not able to replicate these coefficients. However, my linear regression coefficients matches the paper’s probit regression coefficients. It seems like the numbers reported in Table 3 are actually the linear regression coefficients, not the probit regression coefficients. Further investigation is needed to confirm this.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate using a series of t-tests and linear regressions.\n\n#t-test between 1:1 and 2:1 match ratios on the binary outcome of whether any charitable donation was made\ntreatment_gave_1 = data[data['treatment'] == 1]['gave'][data['ratio'] == 1]\ntreatment_gave_2 = data[data['treatment'] == 1]['gave'][data['ratio'] == 2]\n\ndiff = treatment_gave_2.mean() - treatment_gave_1.mean()\n\nt_stat, p_value = ttest_ind(treatment_gave_2, treatment_gave_1)\n\nprint(\"difference in response rates between 1:1 and 2:1 match ratios: \", diff)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ndifference in response rates between 1:1 and 2:1 match ratios:  0.0018842510217149944\nt-statistic:  0.96504713432247\np-value:  0.33453168549723933\n\n\n\n#t-test between 2:1 and 3:1 match ratios on the binary outcome of whether any charitable donation was made\ntreatment_gave_2 = data[data['treatment'] == 1]['gave'][data['ratio'] == 2]\ntreatment_gave_3 = data[data['treatment'] == 1]['gave'][data['ratio'] == 3]\n\ndiff = treatment_gave_3.mean() - treatment_gave_2.mean()\n\nt_stat, p_value = ttest_ind(treatment_gave_3, treatment_gave_2)\n\nprint(\"difference in response rates between 2:1 and 3:1 match ratios: \", diff)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ndifference in response rates between 2:1 and 3:1 match ratios:  0.00010002398025293902\nt-statistic:  0.05011583793874515\np-value:  0.9600305283739325\n\n\n\n#t-test between 1:1 and 3:1 match ratios on the binary outcome of whether any charitable donation was made\ntreatment_gave_1 = data[data['treatment'] == 1]['gave'][data['ratio'] == 1]\ntreatment_gave_3 = data[data['treatment'] == 1]['gave'][data['ratio'] == 3]\n\ndiff = treatment_gave_3.mean() - treatment_gave_1.mean()\n\nt_stat, p_value = ttest_ind(treatment_gave_3, treatment_gave_1)\n\nprint(\"difference in response rates between 1:1 and 3:1 match ratios: \", diff)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ndifference in response rates between 1:1 and 3:1 match ratios:  0.0019842750019679334\nt-statistic:  1.0150255853798622\np-value:  0.3101046637086672\n\n\nThe t-tests and the resulting p-values show that the difference in response rates between the 1:1 and 2:1 match ratios, the 2:1 and 3:1 match ratios, and the 1:1 and 3:1 match ratios are all statistically insignificant at the 95% confidence level. The null hypotheses that the response rates are the same across these groups cannot be rejected.\n\n# Create a new variable 'ratio1' that is equal to 1 if the match ratio is 1:1 and 0 otherwise\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\nmodel = sm.OLS.from_formula('gave ~ ratio1 + ratio2 + ratio3', data=data)\nresults = model.fit()\n#show summary of regression results with just the coefficients and p-values without any notes\nresults.summary().tables[1]\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n0.0179\n0.001\n16.225\n0.000\n0.016\n0.020\n\n\nratio1\n0.0029\n0.002\n1.661\n0.097\n-0.001\n0.006\n\n\nratio2\n0.0048\n0.002\n2.744\n0.006\n0.001\n0.008\n\n\nratio3\n0.0049\n0.002\n2.802\n0.005\n0.001\n0.008\n\n\n\n\n\nThe regression results show that the coefficients for ratio1, ratio2, and ratio3 are all statistically insignificant at the 90% confidence level. Ratio of 1:1 has a p-value of 0.097 which is close to the 90% confidence level. This could suggest that the 1:1 ratio results in a lower response rate compared to the other ratios, although it is not very significant. The p-values for ratio2 and ratio3 are 0.006 and 0.005, suggesting that the 2:1 and 3:1 match ratios do not have a significant effect on the likelihood of making a charitable donation compared to the overall average for the treatment group.\n\n# Calculate the response rate difference between the 1:1 and 2:1 match ratios\ndiff_1_2 = data[(data['treatment'] == 1) & (data['ratio'] == 2)]['gave'].mean() - data[(data['treatment'] == 1) & (data['ratio'] == 1)]['gave'].mean()\n\n# Calculate the response rate difference between the 2:1 and 3:1 match ratios\ndiff_2_3 = data[(data['treatment'] == 1) & (data['ratio'] == 3)]['gave'].mean() - data[(data['treatment'] == 1) & (data['ratio'] == 2)]['gave'].mean()\n\nprint(\"difference in response rates between 1:1 and 2:1 match ratios: \", diff_1_2)\nprint(\"difference in response rates between 2:1 and 3:1 match ratios: \", diff_2_3)\n\ndifference in response rates between 1:1 and 2:1 match ratios:  0.0018842510217149944\ndifference in response rates between 2:1 and 3:1 match ratios:  0.00010002398025293902\n\n\n\n# Calculate the response rate difference between the 1:1 and 2:1 match ratios using the coefficients from the regression\ndiff_1_2_coef = results.params['ratio2'] - results.params['ratio1']\n\n# Calculate the response rate difference between the 2:1 and 3:1 match ratios using the coefficients from the regression\ndiff_2_3_coef = results.params['ratio3'] - results.params['ratio2']\n\nprint(\"difference in response rates between 1:1 and 2:1 match ratios using regression coefficients: \", diff_1_2_coef)\nprint(\"difference in response rates between 2:1 and 3:1 match ratios using regression coefficients: \", diff_2_3_coef)\n\ndifference in response rates between 1:1 and 2:1 match ratios using regression coefficients:  0.0018842510217149775\ndifference in response rates between 2:1 and 3:1 match ratios using regression coefficients:  0.00010002398025295203\n\n\nUsing both linear regression and direct calculation from the data, we find that the difference in response rates between the 1:1 and 2:1 is only 0.12% and the difference in response rates between the 2:1 and 3:1 is only 0.01%. These difference are not statistically significant.\nThis suggests that the size of the matched donation does not have a significant effect on the likelihood of making a charitable donation, given that there is atleast a 1:1 match. This finding is consistent with the results reported in the paper and their interpretation that the size of the matched donation does not have a significant effect on the likelihood of making a charitable donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nFirst, I analyze the difference in donation amounts between treatment and control group regardless of whether a donation was made using t-test and linear regression.\n\n#t-test between treatment and control groups on the donation amount\ntreatment_amount = data[data['treatment'] == 1]['amount']\ncontrol_amount = data[data['control'] == 1]['amount']\n\ndiff = treatment_amount.mean() - control_amount.mean()\n\nt_stat, p_value = ttest_ind(treatment_amount, control_amount)\n\nprint(\"difference in donation amounts between control and treatment: \", diff)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ndifference in donation amounts between control and treatment:  0.1536054\nt-statistic:  1.8605020225753781\np-value:  0.06282038947470686\n\n\n\n#bivariate linear regression of the donation amount on the treatment status\nmodel = sm.OLS.from_formula('amount ~ treatment', data=data)\nresults = model.fit()\n\n#extract the coefficient and p_value on the treatment variable\ncoef = results.params['treatment']\nt_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient: \", coef)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ncoefficient:  0.15360546499194633\nt-statistic:  1.8605026915008567\np-value:  0.06282029492108901\n\n\nThe p-value (.063) for the difference in donation amounts between the treatment and control groups is statistically significant at the 90% confidence level. This suggests that the treatment of receiving a matched donation led to a higher average donation amount.\nNow I will limit the data to just people who made a donation and repeat the previous analysis. This regression allows me to analyze how much respondents donate conditional on donating some positive amount. The regression coefficients will help me interpret the effect of the treatment on the donation amount among people who donated.\n\n#limit the data to just people who made a donation\ndonated_data = data[data['gave'] == 1]\n\n#t-test between treatment and control groups on the donation amount among people who donated\ntreatment_amount = donated_data[donated_data['treatment'] == 1]['amount']\ncontrol_amount = donated_data[donated_data['control'] == 1]['amount']\n\ndiff = treatment_amount.mean() - control_amount.mean()\n\nt_stat, p_value = ttest_ind(treatment_amount, control_amount)\n\nprint(\"difference in donation amounts between control and treatment among people who donated: \", diff)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ndifference in donation amounts between control and treatment among people who donated:  -1.6683922\nt-statistic:  -0.5808388615237938\np-value:  0.5614758782284279\n\n\n\n#bivariate linear regression of the donation amount on the treatment status among people who donated\nmodel = sm.OLS.from_formula('amount ~ treatment', data=donated_data)\nresults = model.fit()\n\n#extract the coefficient and p_value on the treatment variable\ncoef = results.params['treatment']\nt_stat = results.tvalues['treatment']\np_value = results.pvalues['treatment']\n\nprint(\"coefficient: \", coef)\nprint(\"t-statistic: \", t_stat)\nprint(\"p-value: \", p_value)\n\ncoefficient:  -1.6683934553392588\nt-statistic:  -0.5808393091689934\np-value:  0.5614755766155095\n\n\nAmong all the people who donated, those who did not recieve the treatment of matching donation actually donated more on average. However, the p-value (.56) suggests that this difference is not statistically significant. So we cannot conclude that the treatment of receiving a matched donation led to a higher average donation amount among people who donated.\nWe can conclude that if an individual already had the intention to donate with or without the match, the treatment of receiving a matched donation did not lead to a higher average donation amount.\nFinally, I will plot histograms of the donation amounts for the treatment and control groups among people who donated to visualize the distribution.\n\n#plot histogram of donation amounts for the treatment group among people who donated\nplt.hist(donated_data[donated_data['treatment'] == 1]['amount'], bins=20, color='skyblue', edgecolor='black')\nplt.axvline(donated_data[donated_data['treatment'] == 1]['amount'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Donation Amount')\nplt.title('Distribution of Donation Amounts Among People Who Donated (Treatment)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\n#plot histogram of donation amounts for the control group among people who donated\nplt.hist(donated_data[donated_data['control'] == 1]['amount'], bins=20, color='skyblue', edgecolor='black')\nplt.axvline(donated_data[donated_data['control'] == 1]['amount'].mean(), color='red', linestyle='dashed', linewidth=2, label='Mean Donation Amount')\nplt.title('Distribution of Donation Amounts Among People Who Donated (Control)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is clear from the histograms that the actual number of people who donated is higher in the treatment group compared to the control group because the frequency is much higher for the treatment group. However, the average donation amount is slightly higher (insignificant) in the control group and shown with the red dashed line."
  },
  {
    "objectID": "projects/Assignment 1/hw1_questions.html#experimental-results",
    "href": "projects/Assignment 1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/Assignment 1/hw1_questions.html#simulation-experiment",
    "href": "projects/Assignment 1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nWe will simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. We will then calculate the vector of 10,000 differences in the response rates between the treatment and control groups. Finally, we will plot the cumulative average of the vector of differences to demonstrate the Law of Large Numbers.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Separate the treatment and control groups for the \"amount\" variable\ntreatment_amount = data[data['treatment'] == 1]['gave']\ncontrol_amount = data[data['treatment'] == 0]['gave']\n\n# Calculate the true difference in means\ntrue_diff = treatment_amount.mean() - control_amount.mean()\n\nnp.random.seed(0)\n\n# Simulate 100,000 draws from the control distribution\nsimulated_control_draws = np.random.choice(control_amount, 10000, replace=False)\nsimulated_treatment_draws = np.random.choice(treatment_amount, 10000, replace=False)\n\n# Calculate the vector of 10,000 differences\ndifferences = simulated_treatment_draws - simulated_control_draws\n\n# Calculate the cumulative average of the vector of differences\ncumulative_average_differences = np.cumsum(differences) / np.arange(1, 10001)\n\n\nplt.plot(cumulative_average_differences, color='red')\nplt.axhline(y=true_diff, color='black', linestyle='--', label='True Difference in Means')\nplt.xlabel('Number of Draws')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Cumulative Average Differences in Response Rates')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe plot shows the cumulative average of the differences in the mean of “gave” or the response rate between the treatment and control groups as the number of draws increases. The cumulative average approaches the true difference in means as the number of draws increases, which demonstrates the Law of Large Numbers. This means that the more draws we take, the closer the average difference in response rate between the treatment and control groups will be to the true difference in means which is 0.004.\n\n\nCentral Limit Theorem\nWe will simulate 1000 calculations for 50, 200, 500, and 1000 draws from both the control and treatment distributions. We will calculate the average difference in the response rate between the treatment and control groups for each draw. Finally, we will plot histograms of the average differences in the response rates for each sample size to demonstrate the Central Limit Theorem.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntreatment_amount = data[data['treatment'] == 1]['gave']\ncontrol_amount = data[data['treatment'] == 0]['gave']\n\ntrue_diff =  treatment_amount.mean()-control_amount.mean()\nprint('True Difference in the response rate between Control and Treatment:', true_diff)\n\n# Simulate 1000 draws of 50, 200, 500, and 1000 from both the control and treatment distributions\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\nnp.random.seed(0)\n\nfor sample_size in sample_sizes:\n    sample_diffs = []\n    for _ in range(num_simulations):\n        simulated_control_draws = np.random.choice(control_amount, sample_size, replace=False)\n        simulated_treatment_draws = np.random.choice(treatment_amount, sample_size, replace=False)\n        sample_diffs.append(simulated_treatment_draws.mean() - simulated_control_draws.mean())\n\n    plt.hist(sample_diffs, bins=20, color='skyblue', edgecolor='black')\n    plt.axvline(x=true_diff, color='red', linestyle='--', label='True Difference in Response Rate')\n    plt.xlabel('Sample Difference in Response Rates')\n    plt.ylabel('Frequency')\n    plt.title(f'Histogram of Sample Differences in Response Rates (Sample Size = {sample_size})')\n    plt.legend()\n    plt.show()\n\nTrue Difference in the response rate between Control and Treatment: 0.00418035451294875\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe above histogram illustrates the Central Limit Theorem. As the sample size increases, the distribution of the average of differences between the mean becomes normal. The zero is towards middle of the distribution because the true difference in response rates between the control and treament is 0.004."
  },
  {
    "objectID": "projects/Assignment 2/hw2_questions.html",
    "href": "projects/Assignment 2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nWe will start by reading in the data and conducting some exploratory data analysis to understand the data better.\n\nimport pandas as pd\n\ndata = pd.read_csv(\"data/blueprinty.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n1\n0\nMidwest\n32.5\n0\n\n\n1\n786\n3\nSouthwest\n37.5\n0\n\n\n2\n348\n4\nNorthwest\n27.0\n1\n\n\n3\n927\n3\nNortheast\n24.5\n0\n\n\n4\n830\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nmean_patents_customer = data[data['iscustomer'] == 1]['patents'].mean()\nmean_patents_not_customer = data[data['iscustomer'] == 0]['patents'].mean()\n\ndata.groupby(\"iscustomer\")[\"patents\"].hist(alpha=0.5)\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Frequency\")\n#plot mean as vertical line \nplt.axvline(mean_patents_customer, color='orange', linestyle='dashed', linewidth=1)\nplt.axvline(mean_patents_not_customer, color='blue', linestyle='dashed', linewidth=1)\n#add legned for mean\nplt.legend([\"Average patents (customer)\", \"Average patents (non-customer)\", \" Not Customer\", \"Customer\"])\nplt.show()\n\nprint(\"Average number of patents for Blueprinty customers: \", mean_patents_customer)\nprint(\"Average number of patents for non-customers: \", mean_patents_not_customer)\n\n\n\n\n\n\n\n\nAverage number of patents for Blueprinty customers:  4.091370558375634\nAverage number of patents for non-customers:  3.6231772831926325\n\n\nWe will conduct a t-test to determine if the difference in the number of patents awarded is statistically significant by customer status (whether the firm is a customer of Blueprinty or not).\n\nfrom scipy.stats import ttest_ind\n\nttest_ind(data[data['iscustomer'] == 1]['patents'], data[data['iscustomer'] == 0]['patents'])\n\nTtestResult(statistic=2.608522046741729, pvalue=0.009183873913689007, df=1498.0)\n\n\nThe histogram show that there are a lot more non-customers than customers in the dataset. The average number of patents for Blueprinty customers is slightly higher at 4.09 than for non-customers at 3.62. The t-test shows that this difference is statistically significant at the 5% level. However, this analysis does not account for other factors that may influence the number of patents awarded, such as the age and regional location of the firms.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nWe will compare the differences in regions and ages by customer status. We will also conduct t-tests to determine if the differences in proportions of firms in each region and the difference in means of firm ages are statistically significant by customer status.\n\ndata.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True)\nplt.ylabel(\"Proportion of Firms\")\nplt.xlabel(\"Customer Status\")\nplt.title(\"Proportion of Firms by Region\")\nplt.xticks([0, 1], ['Not Customer', 'Customer'], rotation=0)\nplt.show()\n\nmean_age_customer = data[data['iscustomer'] == 1]['age'].mean()\nmean_age_not_customer = data[data['iscustomer'] == 0]['age'].mean()\n\ndata.groupby(\"iscustomer\")[\"age\"].hist(alpha=0.5)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Frequency\")\n#plot mean as vertical line\nplt.axvline(mean_age_customer, color='orange', linestyle='dashed', linewidth=1)\nplt.axvline(mean_age_not_customer, color='blue', linestyle='dashed', linewidth=1)\nplt.legend([\"Mean Age (customer)\", \"Mean Age (non-customer)\", \"Not Customer\", \"Customer\"])\nplt.show()\n\nprint(\"Average firm age of Blueprinty customers: \", mean_age_customer)\nprint(\"Average firm age of non-customers: \", mean_age_not_customer)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAverage firm age of Blueprinty customers:  24.1497461928934\nAverage firm age of non-customers:  26.691481197237145\n\n\nWe conduct multiple t-tests to determine if the difference in proportions of firms in each region is statistically significant by customer status.\n\n# Calculate the proportion of firms in each region by customer status\nregion_proportions = data.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack(fill_value=0)\nprint(\"Region Proportions by Customer Status:\")\nprint(region_proportions)\n\n# T-test for difference in proportions of firms in each region by customer status for each region\nresults = {}\nfor region in region_proportions.columns:\n    # Extracting boolean arrays where each region equals the current region for customers and non-customers\n    customer_region = data[data['iscustomer'] == 1]['region'] == region\n    non_customer_region = data[data['iscustomer'] == 0]['region'] == region\n    \n    # Performing the t-test\n    t_stat, p_value = ttest_ind(customer_region, non_customer_region)\n    results[region] = (t_stat, p_value)\n\nresults\n\nRegion Proportions by Customer Status:\nregion       Midwest  Northeast  Northwest     South  Southwest\niscustomer                                                     \n0           0.158864   0.374520   0.131236  0.131236   0.204144\n1           0.086294   0.573604   0.081218  0.101523   0.157360\n\n\n{'Midwest': (-2.6680681688089445, 0.007711156311267533),\n 'Northeast': (5.361764651187083, 9.532637761137518e-08),\n 'Northwest': (-1.9819710141138518, 0.047664992121595),\n 'South': (-1.1657750023611042, 0.24389100563697513),\n 'Southwest': (-1.5359890421136921, 0.12475224230270916)}\n\n\nWe conduct a t-test to determine if the difference in means of firm ages is statistically significant by customer status.\n\nttest_ind(data[data['iscustomer'] == 1]['age'], data[data['iscustomer'] == 0]['age'])\n\nTtestResult(statistic=-4.621997648306684, pvalue=4.127085667816596e-06, df=1498.0)\n\n\nThe t-tests shows that the difference in proportions of firms in each region is statistically significant for the Midwest, Northeast, and Northwest regions at the 5% level. The t-test on average age of the firm shows that the difference in means of firm ages is statistically significant at the 5% level.\nTherefore, we should account for these differences in our analysis. We cannot conclude that the difference in the number of patents awarded is due to Blueprinty’s software without controlling for these differences.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nWe will write down the log-likelihood function for \\(Y \\sim \\text{Poisson}(\\lambda)\\) given the Poisson probability density function of \\((Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nThe log-likelihood function for a sample \\(( Y_1, Y_2, \\ldots, Y_n)\\) from a Poisson distribution with parameter \\(( \\lambda)\\) is given by:\n\\(\\ell(\\lambda; y_1, y_2, \\ldots, y_n) = \\sum_{i=1}^n y_i \\log(\\lambda) - n\\lambda - \\sum_{i=1}^n \\log(y_i!)\\)\nNext, we will code the log-likelihood function for the Poisson model. This is a function of lambda and Y. The function should return the log-likelihood value for a given rate parameter lambda and a set of observed counts Y.\n\nimport numpy as np\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Calculate the log likelihood for a Poisson distributed set of observed counts, Y, given a rate lambda_,\n    without using gammaln for factorial computation.\n\n    Parameters:\n    lambda_ : float\n        The rate parameter of the Poisson distribution (lambda &gt; 0).\n    Y : array_like\n        Array of observed counts (non-negative integers).\n\n    Returns:\n    float\n        The log likelihood value.\n    \"\"\"\n    if lambda_ &lt;= 0:\n        return -np.inf  # log likelihood is undefined for non-positive lambda\n    Y = np.asarray(Y)\n    log_factorials = np.array([np.sum(np.log(np.arange(1, y+1))) if y &gt; 0 else 0 for y in Y])\n    return np.sum(Y * np.log(lambda_) - lambda_ - log_factorials)\n\nWe will use the above function to plot a range of lambdas (0.1-10) on the horizontal axis and the log likelihood on the vertical axis. We will use the observed patent counts as Y. The maximum likelihood estimate (MLE) of lambda is the value that maximizes the log-likelihood function.\n\nY = data['patents'].values  # Extracting patent counts\n\n# Define the range of lambda values from a small positive number up to a reasonable upper limit\nlambda_values = np.linspace(0.1, 10, 400)  # from 0.1 to 10, 400 points\nlog_likelihoods = [poisson_loglikelihood(l, Y) for l in lambda_values]\n\n# Plotting the results\nplt.plot(lambda_values, log_likelihoods, label='Log-Likelihood')\nplt.title('Log-Likelihood of Lambda for Observed Patent Counts')\nplt.xlabel('Lambda (Rate Parameter)')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nWe will use optimization to find the MLE of lambda. We will use the scipy.optimize.minimize function to minimize the negative log-likelihood function. The negative log-likelihood is the negative of the log-likelihood function, which we want to minimize. We will set the bounds of the optimization to ensure that lambda is positive.\nWe will also calculate the mean number of patents per firm which should be close to the MLE of lambda since the Poisson distribution has only one parameter which is the rate parameter lambda. The mean of a Poisson distribution is equal to its rate parameter.\n\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\ndef negative_log_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:  # Log-likelihood undefined for non-positive lambda values\n        return np.inf\n    return -np.sum(Y * np.log(lambda_) - lambda_ - gammaln(Y + 1))\n\nY =  data['patents'].values\n\n# Find MLE for lambda using optimization\nresult = minimize(fun=negative_log_likelihood, x0=np.array([1]), args=(Y,), bounds=[(0.1, None)])\n\n# Output the results\nif result.success:\n    print(f\"MLE for lambda (lambda_mle): {result.x[0]}\")\nelse:\n    print(\"Optimization failed:\", result.message)\n\n\nmean_patents = np.mean(Y)\nprint(\"Mean number of patents per firm: \", mean_patents)\n\nMLE for lambda (lambda_mle): 3.6846664821737423\nMean number of patents per firm:  3.6846666666666668\n\n\nAs expected, the MLE of lambda is the same as the average number of patents per firm. This is because the Poisson distribution has only one parameter, the rate parameter lambda, which is equal to the mean of the distribution.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nWe will Update our log-likelihood function with an additional argument to take in a covariate matrix X. We will also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\).\nWe will make sure that the first column of X are all 1’s to enable a constant term in the model, and the subsequent columns are age, age squared, binary variables for all but one of the regions, and the binary iscustomer variable.\n\nimport statsmodels.api as sm\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age'] ** 2  # Add age squared\ndata = pd.get_dummies(data, columns=['region'], drop_first=True)  # One-hot encode region\n\nX = np.column_stack([\n    np.ones(len(data)),  # Intercept\n    data['age'],\n    data['age_squared'],\n    data['iscustomer']\n] + [data[col] for col in data.columns if 'region_' in col])\n\nY = data['patents'].values\n\ndef neg_log_likelihood(beta, Y, X):\n    eta = np.dot(X, beta)\n    lambda_i = np.exp(eta)\n    log_likelihood = np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n    return -log_likelihood  # Minimize this\n\n\n\nbeta_initial = np.zeros(X.shape[1])  # Initial guess for the parameters\n\nneg_log_likelihood(beta_initial, Y, X)\n\n6548.8869900694435\n\n\nNext, we will use the updated function with scipy.optimize to find the MLE vector and the Hessian of the Poisson model with covariates. We will use the Hessian to find standard errors of the beta parameter.\n\nfrom scipy.optimize import minimize\nimport numpy as np\n\n# Scale features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X[:, 1:])  # Assuming first column is intercept\nX_scaled = np.hstack((np.ones((X.shape[0], 1)), X_scaled))  # Add intercept back\n\n# Change optimization method and adjust initial guesses\nbeta_initial = np.random.normal(loc=0.0, scale=0.1, size=X.shape[1])  #\n\n\nresult = minimize(\n    neg_log_likelihood, beta_initial, args=(Y, X_scaled),\n    method='L-BFGS-B', options={'disp': True, 'maxiter': 500}\n)\n\nif result.success:\n    beta_mle = result.x\n    print(\"MLE of beta:\", beta_mle)\nelse:\n    print(\"Optimization failed:\", result.message)\n\nMLE of beta: [ 1.28539574  1.04645803 -1.14084402  0.03989475  0.04831526 -0.00663774\n  0.01905762  0.02046153]\n\n\n\nhessian_matrix = result.hess_inv.todense()\nstd_errors = np.sqrt(np.diag(hessian_matrix))\nprint(\"Standard errors:\", std_errors)\n\nStandard errors: [0.77517876 0.93643018 0.85862749 0.17524838 0.51392824 0.49658911\n 0.9191293  0.52649659]\n\n\n\ncoefficients_table = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Standard Error': std_errors\n}, index=['Intercept', 'Age', 'Age Squared', 'Is Customer'] + [f'Region_{i}' for i in range(len(std_errors) - 4)])\nprint(coefficients_table)\n\n             Coefficient  Standard Error\nIntercept       1.285396        0.775179\nAge             1.046458        0.936430\nAge Squared    -1.140844        0.858627\nIs Customer     0.039895        0.175248\nRegion_0        0.048315        0.513928\nRegion_1       -0.006638        0.496589\nRegion_2        0.019058        0.919129\nRegion_3        0.020462        0.526497\n\n\nWe will verify the results using Python’s sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Create the GLM model with Poisson family\npoisson_model = sm.GLM(Y, X_scaled, family=sm.families.Poisson())\n\n# Fit the model\nresult = poisson_model.fit()\n\n# Print the summary of the model to see the results\nprint(result.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3275.9\nDate:                Wed, 01 May 2024   Deviance:                       2178.8\nTime:                        21:31:53   Pearson chi2:                 2.11e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1152\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.2854      0.014     93.584      0.000       1.258       1.312\nx1             1.0465      0.100     10.414      0.000       0.850       1.243\nx2            -1.1408      0.102    -11.131      0.000      -1.342      -0.940\nx3             0.0399      0.013      3.035      0.002       0.014       0.066\nx4             0.0483      0.021      2.347      0.019       0.008       0.089\nx5            -0.0066      0.018     -0.374      0.709      -0.041       0.028\nx6             0.0191      0.018      1.085      0.278      -0.015       0.053\nx7             0.0205      0.019      1.088      0.277      -0.016       0.057\n==============================================================================\n\n\nBased on the Poisson regression model, the coefficients provide insights into the relationship between the covariates and the number of patents awarded. The coefficients for age and age squared are large and very significant suggesting that age of the firm has a significant impact on the number of patents awarded. The coefficient for the iscustomer variable is positive, indicating that firms using Blueprinty’s software tend to have more patents awarded but the coefficient is much smaller than the age coefficient, suggesting that age is a more significant factor. The coefficients for the region variables are small and not statistically significant, indicating that regional location may not have a significant impact on the number of patents awarded.\nEven though the average firm age of Blueprinty customers is lower than non-customers, the average number of patents awarded to customers is higher. This suggests that Blueprinty’s software may be associated with higher patent awards even after accounting for the age factor."
  },
  {
    "objectID": "projects/Assignment 2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/Assignment 2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nWe will start by reading in the data and conducting some exploratory data analysis to understand the data better.\n\nimport pandas as pd\n\ndata = pd.read_csv(\"data/blueprinty.csv\")\ndata.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n1\n0\nMidwest\n32.5\n0\n\n\n1\n786\n3\nSouthwest\n37.5\n0\n\n\n2\n348\n4\nNorthwest\n27.0\n1\n\n\n3\n927\n3\nNortheast\n24.5\n0\n\n\n4\n830\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nmean_patents_customer = data[data['iscustomer'] == 1]['patents'].mean()\nmean_patents_not_customer = data[data['iscustomer'] == 0]['patents'].mean()\n\ndata.groupby(\"iscustomer\")[\"patents\"].hist(alpha=0.5)\nplt.xlabel(\"Number of Patents\")\nplt.ylabel(\"Frequency\")\n#plot mean as vertical line \nplt.axvline(mean_patents_customer, color='orange', linestyle='dashed', linewidth=1)\nplt.axvline(mean_patents_not_customer, color='blue', linestyle='dashed', linewidth=1)\n#add legned for mean\nplt.legend([\"Average patents (customer)\", \"Average patents (non-customer)\", \" Not Customer\", \"Customer\"])\nplt.show()\n\nprint(\"Average number of patents for Blueprinty customers: \", mean_patents_customer)\nprint(\"Average number of patents for non-customers: \", mean_patents_not_customer)\n\n\n\n\n\n\n\n\nAverage number of patents for Blueprinty customers:  4.091370558375634\nAverage number of patents for non-customers:  3.6231772831926325\n\n\nWe will conduct a t-test to determine if the difference in the number of patents awarded is statistically significant by customer status (whether the firm is a customer of Blueprinty or not).\n\nfrom scipy.stats import ttest_ind\n\nttest_ind(data[data['iscustomer'] == 1]['patents'], data[data['iscustomer'] == 0]['patents'])\n\nTtestResult(statistic=2.608522046741729, pvalue=0.009183873913689007, df=1498.0)\n\n\nThe histogram show that there are a lot more non-customers than customers in the dataset. The average number of patents for Blueprinty customers is slightly higher at 4.09 than for non-customers at 3.62. The t-test shows that this difference is statistically significant at the 5% level. However, this analysis does not account for other factors that may influence the number of patents awarded, such as the age and regional location of the firms.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nWe will compare the differences in regions and ages by customer status. We will also conduct t-tests to determine if the differences in proportions of firms in each region and the difference in means of firm ages are statistically significant by customer status.\n\ndata.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True)\nplt.ylabel(\"Proportion of Firms\")\nplt.xlabel(\"Customer Status\")\nplt.title(\"Proportion of Firms by Region\")\nplt.xticks([0, 1], ['Not Customer', 'Customer'], rotation=0)\nplt.show()\n\nmean_age_customer = data[data['iscustomer'] == 1]['age'].mean()\nmean_age_not_customer = data[data['iscustomer'] == 0]['age'].mean()\n\ndata.groupby(\"iscustomer\")[\"age\"].hist(alpha=0.5)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Frequency\")\n#plot mean as vertical line\nplt.axvline(mean_age_customer, color='orange', linestyle='dashed', linewidth=1)\nplt.axvline(mean_age_not_customer, color='blue', linestyle='dashed', linewidth=1)\nplt.legend([\"Mean Age (customer)\", \"Mean Age (non-customer)\", \"Not Customer\", \"Customer\"])\nplt.show()\n\nprint(\"Average firm age of Blueprinty customers: \", mean_age_customer)\nprint(\"Average firm age of non-customers: \", mean_age_not_customer)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAverage firm age of Blueprinty customers:  24.1497461928934\nAverage firm age of non-customers:  26.691481197237145\n\n\nWe conduct multiple t-tests to determine if the difference in proportions of firms in each region is statistically significant by customer status.\n\n# Calculate the proportion of firms in each region by customer status\nregion_proportions = data.groupby(\"iscustomer\")[\"region\"].value_counts(normalize=True).unstack(fill_value=0)\nprint(\"Region Proportions by Customer Status:\")\nprint(region_proportions)\n\n# T-test for difference in proportions of firms in each region by customer status for each region\nresults = {}\nfor region in region_proportions.columns:\n    # Extracting boolean arrays where each region equals the current region for customers and non-customers\n    customer_region = data[data['iscustomer'] == 1]['region'] == region\n    non_customer_region = data[data['iscustomer'] == 0]['region'] == region\n    \n    # Performing the t-test\n    t_stat, p_value = ttest_ind(customer_region, non_customer_region)\n    results[region] = (t_stat, p_value)\n\nresults\n\nRegion Proportions by Customer Status:\nregion       Midwest  Northeast  Northwest     South  Southwest\niscustomer                                                     \n0           0.158864   0.374520   0.131236  0.131236   0.204144\n1           0.086294   0.573604   0.081218  0.101523   0.157360\n\n\n{'Midwest': (-2.6680681688089445, 0.007711156311267533),\n 'Northeast': (5.361764651187083, 9.532637761137518e-08),\n 'Northwest': (-1.9819710141138518, 0.047664992121595),\n 'South': (-1.1657750023611042, 0.24389100563697513),\n 'Southwest': (-1.5359890421136921, 0.12475224230270916)}\n\n\nWe conduct a t-test to determine if the difference in means of firm ages is statistically significant by customer status.\n\nttest_ind(data[data['iscustomer'] == 1]['age'], data[data['iscustomer'] == 0]['age'])\n\nTtestResult(statistic=-4.621997648306684, pvalue=4.127085667816596e-06, df=1498.0)\n\n\nThe t-tests shows that the difference in proportions of firms in each region is statistically significant for the Midwest, Northeast, and Northwest regions at the 5% level. The t-test on average age of the firm shows that the difference in means of firm ages is statistically significant at the 5% level.\nTherefore, we should account for these differences in our analysis. We cannot conclude that the difference in the number of patents awarded is due to Blueprinty’s software without controlling for these differences.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nWe will write down the log-likelihood function for \\(Y \\sim \\text{Poisson}(\\lambda)\\) given the Poisson probability density function of \\((Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nThe log-likelihood function for a sample \\(( Y_1, Y_2, \\ldots, Y_n)\\) from a Poisson distribution with parameter \\(( \\lambda)\\) is given by:\n\\(\\ell(\\lambda; y_1, y_2, \\ldots, y_n) = \\sum_{i=1}^n y_i \\log(\\lambda) - n\\lambda - \\sum_{i=1}^n \\log(y_i!)\\)\nNext, we will code the log-likelihood function for the Poisson model. This is a function of lambda and Y. The function should return the log-likelihood value for a given rate parameter lambda and a set of observed counts Y.\n\nimport numpy as np\n\ndef poisson_loglikelihood(lambda_, Y):\n    \"\"\"\n    Calculate the log likelihood for a Poisson distributed set of observed counts, Y, given a rate lambda_,\n    without using gammaln for factorial computation.\n\n    Parameters:\n    lambda_ : float\n        The rate parameter of the Poisson distribution (lambda &gt; 0).\n    Y : array_like\n        Array of observed counts (non-negative integers).\n\n    Returns:\n    float\n        The log likelihood value.\n    \"\"\"\n    if lambda_ &lt;= 0:\n        return -np.inf  # log likelihood is undefined for non-positive lambda\n    Y = np.asarray(Y)\n    log_factorials = np.array([np.sum(np.log(np.arange(1, y+1))) if y &gt; 0 else 0 for y in Y])\n    return np.sum(Y * np.log(lambda_) - lambda_ - log_factorials)\n\nWe will use the above function to plot a range of lambdas (0.1-10) on the horizontal axis and the log likelihood on the vertical axis. We will use the observed patent counts as Y. The maximum likelihood estimate (MLE) of lambda is the value that maximizes the log-likelihood function.\n\nY = data['patents'].values  # Extracting patent counts\n\n# Define the range of lambda values from a small positive number up to a reasonable upper limit\nlambda_values = np.linspace(0.1, 10, 400)  # from 0.1 to 10, 400 points\nlog_likelihoods = [poisson_loglikelihood(l, Y) for l in lambda_values]\n\n# Plotting the results\nplt.plot(lambda_values, log_likelihoods, label='Log-Likelihood')\nplt.title('Log-Likelihood of Lambda for Observed Patent Counts')\nplt.xlabel('Lambda (Rate Parameter)')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nWe will use optimization to find the MLE of lambda. We will use the scipy.optimize.minimize function to minimize the negative log-likelihood function. The negative log-likelihood is the negative of the log-likelihood function, which we want to minimize. We will set the bounds of the optimization to ensure that lambda is positive.\nWe will also calculate the mean number of patents per firm which should be close to the MLE of lambda since the Poisson distribution has only one parameter which is the rate parameter lambda. The mean of a Poisson distribution is equal to its rate parameter.\n\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\ndef negative_log_likelihood(lambda_, Y):\n    if lambda_ &lt;= 0:  # Log-likelihood undefined for non-positive lambda values\n        return np.inf\n    return -np.sum(Y * np.log(lambda_) - lambda_ - gammaln(Y + 1))\n\nY =  data['patents'].values\n\n# Find MLE for lambda using optimization\nresult = minimize(fun=negative_log_likelihood, x0=np.array([1]), args=(Y,), bounds=[(0.1, None)])\n\n# Output the results\nif result.success:\n    print(f\"MLE for lambda (lambda_mle): {result.x[0]}\")\nelse:\n    print(\"Optimization failed:\", result.message)\n\n\nmean_patents = np.mean(Y)\nprint(\"Mean number of patents per firm: \", mean_patents)\n\nMLE for lambda (lambda_mle): 3.6846664821737423\nMean number of patents per firm:  3.6846666666666668\n\n\nAs expected, the MLE of lambda is the same as the average number of patents per firm. This is because the Poisson distribution has only one parameter, the rate parameter lambda, which is equal to the mean of the distribution.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nWe will Update our log-likelihood function with an additional argument to take in a covariate matrix X. We will also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that_ \\(\\lambda_i = e^{X_i'\\beta}\\).\nWe will make sure that the first column of X are all 1’s to enable a constant term in the model, and the subsequent columns are age, age squared, binary variables for all but one of the regions, and the binary iscustomer variable.\n\nimport statsmodels.api as sm\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age'] ** 2  # Add age squared\ndata = pd.get_dummies(data, columns=['region'], drop_first=True)  # One-hot encode region\n\nX = np.column_stack([\n    np.ones(len(data)),  # Intercept\n    data['age'],\n    data['age_squared'],\n    data['iscustomer']\n] + [data[col] for col in data.columns if 'region_' in col])\n\nY = data['patents'].values\n\ndef neg_log_likelihood(beta, Y, X):\n    eta = np.dot(X, beta)\n    lambda_i = np.exp(eta)\n    log_likelihood = np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n    return -log_likelihood  # Minimize this\n\n\n\nbeta_initial = np.zeros(X.shape[1])  # Initial guess for the parameters\n\nneg_log_likelihood(beta_initial, Y, X)\n\n6548.8869900694435\n\n\nNext, we will use the updated function with scipy.optimize to find the MLE vector and the Hessian of the Poisson model with covariates. We will use the Hessian to find standard errors of the beta parameter.\n\nfrom scipy.optimize import minimize\nimport numpy as np\n\n# Scale features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X[:, 1:])  # Assuming first column is intercept\nX_scaled = np.hstack((np.ones((X.shape[0], 1)), X_scaled))  # Add intercept back\n\n# Change optimization method and adjust initial guesses\nbeta_initial = np.random.normal(loc=0.0, scale=0.1, size=X.shape[1])  #\n\n\nresult = minimize(\n    neg_log_likelihood, beta_initial, args=(Y, X_scaled),\n    method='L-BFGS-B', options={'disp': True, 'maxiter': 500}\n)\n\nif result.success:\n    beta_mle = result.x\n    print(\"MLE of beta:\", beta_mle)\nelse:\n    print(\"Optimization failed:\", result.message)\n\nMLE of beta: [ 1.28539574  1.04645803 -1.14084402  0.03989475  0.04831526 -0.00663774\n  0.01905762  0.02046153]\n\n\n\nhessian_matrix = result.hess_inv.todense()\nstd_errors = np.sqrt(np.diag(hessian_matrix))\nprint(\"Standard errors:\", std_errors)\n\nStandard errors: [0.77517876 0.93643018 0.85862749 0.17524838 0.51392824 0.49658911\n 0.9191293  0.52649659]\n\n\n\ncoefficients_table = pd.DataFrame({\n    'Coefficient': beta_mle,\n    'Standard Error': std_errors\n}, index=['Intercept', 'Age', 'Age Squared', 'Is Customer'] + [f'Region_{i}' for i in range(len(std_errors) - 4)])\nprint(coefficients_table)\n\n             Coefficient  Standard Error\nIntercept       1.285396        0.775179\nAge             1.046458        0.936430\nAge Squared    -1.140844        0.858627\nIs Customer     0.039895        0.175248\nRegion_0        0.048315        0.513928\nRegion_1       -0.006638        0.496589\nRegion_2        0.019058        0.919129\nRegion_3        0.020462        0.526497\n\n\nWe will verify the results using Python’s sm.GLM() function.\n\nimport statsmodels.api as sm\n\n# Create the GLM model with Poisson family\npoisson_model = sm.GLM(Y, X_scaled, family=sm.families.Poisson())\n\n# Fit the model\nresult = poisson_model.fit()\n\n# Print the summary of the model to see the results\nprint(result.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3275.9\nDate:                Wed, 01 May 2024   Deviance:                       2178.8\nTime:                        21:31:53   Pearson chi2:                 2.11e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1152\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.2854      0.014     93.584      0.000       1.258       1.312\nx1             1.0465      0.100     10.414      0.000       0.850       1.243\nx2            -1.1408      0.102    -11.131      0.000      -1.342      -0.940\nx3             0.0399      0.013      3.035      0.002       0.014       0.066\nx4             0.0483      0.021      2.347      0.019       0.008       0.089\nx5            -0.0066      0.018     -0.374      0.709      -0.041       0.028\nx6             0.0191      0.018      1.085      0.278      -0.015       0.053\nx7             0.0205      0.019      1.088      0.277      -0.016       0.057\n==============================================================================\n\n\nBased on the Poisson regression model, the coefficients provide insights into the relationship between the covariates and the number of patents awarded. The coefficients for age and age squared are large and very significant suggesting that age of the firm has a significant impact on the number of patents awarded. The coefficient for the iscustomer variable is positive, indicating that firms using Blueprinty’s software tend to have more patents awarded but the coefficient is much smaller than the age coefficient, suggesting that age is a more significant factor. The coefficients for the region variables are small and not statistically significant, indicating that regional location may not have a significant impact on the number of patents awarded.\nEven though the average firm age of Blueprinty customers is lower than non-customers, the average number of patents awarded to customers is higher. This suggests that Blueprinty’s software may be associated with higher patent awards even after accounting for the age factor."
  },
  {
    "objectID": "projects/Assignment 2/hw2_questions.html#airbnb-case-study",
    "href": "projects/Assignment 2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided.\nWe will start by reading in the data\n\nairbnb_data = pd.read_csv(\"data/airbnb.csv\")\n\n# Display the first few rows and summary statistics\nairbnb_data.head(), airbnb_data.describe()\n\n(   Unnamed: 0    id  days last_scraped  host_since        room_type  \\\n 0           1  2515  3130     4/2/2017    9/6/2008     Private room   \n 1           2  2595  3127     4/2/2017    9/9/2008  Entire home/apt   \n 2           3  3647  3050     4/2/2017  11/25/2008     Private room   \n 3           4  3831  3038     4/2/2017   12/7/2008  Entire home/apt   \n 4           5  4611  3012     4/2/2017    1/2/2009     Private room   \n \n    bathrooms  bedrooms  price  number_of_reviews  review_scores_cleanliness  \\\n 0        1.0       1.0     59                150                        9.0   \n 1        1.0       0.0    230                 20                        9.0   \n 2        1.0       1.0    150                  0                        NaN   \n 3        1.0       1.0     89                116                        9.0   \n 4        NaN       1.0     39                 93                        9.0   \n \n    review_scores_location  review_scores_value instant_bookable  \n 0                     9.0                  9.0                f  \n 1                    10.0                  9.0                f  \n 2                     NaN                  NaN                f  \n 3                     9.0                  9.0                f  \n 4                     8.0                  9.0                t  ,\n          Unnamed: 0            id          days     bathrooms      bedrooms  \\\n count  40628.000000  4.062800e+04  40628.000000  40468.000000  40552.000000   \n mean   20314.500000  9.698889e+06   1102.368219      1.124592      1.147046   \n std    11728.437705  5.460166e+06   1383.269358      0.385884      0.691746   \n min        1.000000  2.515000e+03      1.000000      0.000000      0.000000   \n 25%    10157.750000  4.889868e+06    542.000000      1.000000      1.000000   \n 50%    20314.500000  9.862878e+06    996.000000      1.000000      1.000000   \n 75%    30471.250000  1.466789e+07   1535.000000      1.000000      1.000000   \n max    40628.000000  1.800967e+07  42828.000000      8.000000     10.000000   \n \n               price  number_of_reviews  review_scores_cleanliness  \\\n count  40628.000000       40628.000000               30433.000000   \n mean     144.760732          15.904426                   9.198370   \n std      210.657597          29.246009                   1.119935   \n min       10.000000           0.000000                   2.000000   \n 25%       70.000000           1.000000                   9.000000   \n 50%      100.000000           4.000000                  10.000000   \n 75%      170.000000          17.000000                  10.000000   \n max    10000.000000         421.000000                  10.000000   \n \n        review_scores_location  review_scores_value  \n count            30374.000000         30372.000000  \n mean                 9.413544             9.331522  \n std                  0.844949             0.902966  \n min                  2.000000             2.000000  \n 25%                  9.000000             9.000000  \n 50%                 10.000000            10.000000  \n 75%                 10.000000            10.000000  \n max                 10.000000            10.000000  )\n\n\nWe will perform some data cleaning and transformation. We will convert date columns to datetime format, remove rows with missing values in host_since column since it has only 35 missing values, fill missing values for bathrooms and bedrooms (160 and 76 missing rows, respectively) with median, handle missing review scores by filling with median, convert instant_bookable to boolean, and remove the unnamed: 0 column.\n\n# Convert date columns to datetime format\nairbnb_data['last_scraped'] = pd.to_datetime(airbnb_data['last_scraped'], format='%m/%d/%Y')\nairbnb_data['host_since'] = pd.to_datetime(airbnb_data['host_since'], format='%m/%d/%Y')\n\n# remove rows with missing values in host_since column\nairbnb_data.dropna(subset=['host_since'], inplace=True)\n\n# Fill missing values for bathrooms and bedrooms with median\nairbnb_data['bathrooms'].fillna(airbnb_data['bathrooms'].median(), inplace=True)\nairbnb_data['bedrooms'].fillna(airbnb_data['bedrooms'].median(), inplace=True)\n\n# Handling missing review scores by filling with median\nfor column in ['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']:\n    airbnb_data[column].fillna(airbnb_data[column].median(), inplace=True)\n\n# convert instant_bookable to boolean. 't' = True, 'f' = False\nairbnb_data['instant_bookable'] = airbnb_data['instant_bookable'].map({'t': True, 'f': False})\n\n# remove unnamed: 0 column\nairbnb_data.drop('Unnamed: 0', axis=1, inplace=True)\n\n# Check for any remaining missing values and verify transformations\nairbnb_data.isnull().sum(), airbnb_data.head()\n\n(id                           0\n days                         0\n last_scraped                 0\n host_since                   0\n room_type                    0\n bathrooms                    0\n bedrooms                     0\n price                        0\n number_of_reviews            0\n review_scores_cleanliness    0\n review_scores_location       0\n review_scores_value          0\n instant_bookable             0\n dtype: int64,\n      id  days last_scraped host_since        room_type  bathrooms  bedrooms  \\\n 0  2515  3130   2017-04-02 2008-09-06     Private room        1.0       1.0   \n 1  2595  3127   2017-04-02 2008-09-09  Entire home/apt        1.0       0.0   \n 2  3647  3050   2017-04-02 2008-11-25     Private room        1.0       1.0   \n 3  3831  3038   2017-04-02 2008-12-07  Entire home/apt        1.0       1.0   \n 4  4611  3012   2017-04-02 2009-01-02     Private room        1.0       1.0   \n \n    price  number_of_reviews  review_scores_cleanliness  \\\n 0     59                150                        9.0   \n 1    230                 20                        9.0   \n 2    150                  0                       10.0   \n 3     89                116                        9.0   \n 4     39                 93                        9.0   \n \n    review_scores_location  review_scores_value  instant_bookable  \n 0                     9.0                  9.0             False  \n 1                    10.0                  9.0             False  \n 2                    10.0                 10.0             False  \n 3                     9.0                  9.0             False  \n 4                     8.0                  9.0              True  )\n\n\nWe will perform some exploratory data analysis to get a feel for the data. We will plot histograms of key variables and a boxplot of price by room type.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setting up the aesthetics for plots\nsns.set(style=\"whitegrid\")\n\n# Creating a figure to plot distributions of key variables\nfig, axes = plt.subplots(2, 2, figsize=(14, 12))\n\n# Distribution of 'number_of_reviews'\nsns.histplot(airbnb_data['number_of_reviews'], bins=30, ax=axes[0, 0], kde=False, color='blue')\naxes[0, 0].set_title('Distribution of Number of Reviews')\naxes[0, 0].set_xlabel('Number of Reviews')\naxes[0, 0].set_ylabel('Frequency')\n\n# Distribution of 'price'\nsns.histplot(airbnb_data['price'], bins=30, ax=axes[0, 1], kde=False, color='green')\naxes[0, 1].set_title('Distribution of Price')\naxes[0, 1].set_xlabel('Price ($ per night)')\naxes[0, 1].set_ylabel('Frequency')\n\n# Distribution of 'review_scores_cleanliness'\nsns.histplot(airbnb_data['review_scores_cleanliness'], bins=9, ax=axes[1, 0], kde=False, color='red')\naxes[1, 0].set_title('Distribution of Cleanliness Scores')\naxes[1, 0].set_xlabel('Cleanliness Score')\naxes[1, 0].set_ylabel('Frequency')\n\n# Boxplot of price by room type\nsns.boxplot(data=airbnb_data, x='room_type', y='price', ax=axes[1, 1])\naxes[1, 1].set_title('Price Distribution by Room Type')\naxes[1, 1].set_xlabel('Room Type')\naxes[1, 1].set_ylabel('Price ($ per night)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFinally, we will build a Poisson regression model for the number of reviews as a function of the variables provided. We will use the number_of_reviews as the dependent variable and days, room_type, bathrooms, bedrooms, price, review_scores_cleanliness, review_scores_location, review_scores_value, and instant_bookable as independent variables. We will one-hot encode the room_type variable, standardize the features, and use the scipy.optimize.minimize function to find the MLE of the beta coefficients.\n\nfrom math import exp\n\n# Drop rows with missing values in relevant columns\ncolumns_to_keep = ['days', 'room_type', 'bathrooms', 'bedrooms', 'price', \n                   'review_scores_cleanliness', 'review_scores_location', \n                   'review_scores_value', 'instant_bookable', 'number_of_reviews']\n\ndata_clean = airbnb_data[columns_to_keep]\n\n# One-hot encode categorical variables\ndata_clean = pd.get_dummies(data_clean, columns=['room_type'], drop_first=True)\n\n\n# Separate features and target\nfeatures = [col for col in data_clean.columns if col != 'number_of_reviews']\nX = data_clean[features].values\nY = data_clean['number_of_reviews'].values\n\n# Add intercept column\nX = np.column_stack([np.ones(X.shape[0]), X])\n\n# Standardize features (excluding intercept)\nscaler = StandardScaler()\nX[:, 1:] = scaler.fit_transform(X[:, 1:])\n\n# Define a custom function for exponentiation\ndef custom_exp(arr):\n    return np.array([exp(x) for x in arr])\n\n# Define the negative log-likelihood function for Poisson regression\ndef neg_log_likelihood(beta, Y, X):\n    eta = np.dot(X, beta)\n    lambda_i = custom_exp(eta)  # Use the custom exponentiation function\n    log_likelihood = np.sum(Y * np.log(lambda_i) - lambda_i - gammaln(Y + 1))\n    return -log_likelihood\n\n# Initial guess for parameters\nbeta_initial = np.zeros(X.shape[1])\n\n# Optimize to find the MLE of beta\nresult = minimize(neg_log_likelihood, beta_initial, args=(Y, X), method='L-BFGS-B', options={'disp': True, 'maxiter': 500})\n\n# Extract results\nif result.success:\n    beta_mle = result.x\nelse:\n    print(\"Optimization failed:\", result.message)\n\n# Get coefficient names\ncoeff_names = ['Intercept'] + features\n\n# Create a DataFrame to hold coefficients\ncoef_df = pd.DataFrame({'Coefficient': coeff_names, 'Estimate': beta_mle})\n\n# Display the coefficients\nprint(coef_df)\n\n                  Coefficient  Estimate\n0                   Intercept  2.638190\n1                        days  0.401703\n2                   bathrooms -0.041503\n3                    bedrooms  0.047976\n4                       price -0.052433\n5   review_scores_cleanliness  0.042785\n6      review_scores_location -0.137250\n7         review_scores_value -0.128118\n8            instant_bookable  0.192071\n9      room_type_Private room -0.046005\n10      room_type_Shared room -0.039299\n\n\n\n\nInterpretation of Results\nThe Poisson regression model provides estimates for the coefficients of the model. The coefficients represent the log of the rate of reviews for each unit. The interpretation of the coefficients is as follows:\nIntercept (2.64): Represents the baseline log count of bookings (as proxied by reviews) for the reference level of categorical variables when all other variables are at their reference levels or zero.\nDays (0.40): A positive coefficient indicates that as the number of days since the listing was created increases, the expected number of bookings increases. Specifically, for each additional day, the expected log count of bookings increases by approximately 0.40. This suggests that older listings tend to have more bookings, possibly due to accumulating reviews and gaining more visibility.\nBathrooms (-0.04): A negative coefficient means that as the number of bathrooms increases, the expected number of bookings decreases. This might suggest that the number of bathrooms isn’t a significant factor influencing bookings or that properties with more bathrooms have a different appeal.\nBedrooms (0.05): A positive coefficient suggests that as the number of bedrooms increases, the expected number of bookings increases. This implies that larger properties (in terms of bedrooms) tend to attract more bookings, likely because they accommodate more guests.\nPrice (-0.05): A small negative coefficient suggests that an increase in the listing price is associated with a slight decrease in the expected number of bookings. Higher prices may deter some potential customers, leading to fewer bookings.\nReview Score Cleanliness (0.04): A positive coefficient indicates that as the cleanliness score increases, the expected number of bookings increases. This means that customers value cleanliness, and highly-rated properties tend to have more bookings.\nReview Score Location (-0.14): A negative coefficient implies that higher location scores are associated with fewer bookings. While counterintuitive, this may indicate that other factors might be overshadowing location, or that listings in prime locations are more competitive.\nReview Score Value (-0.13): A negative coefficient means that higher value scores are associated with fewer bookings. This could imply that while customers value “value for money,” this factor alone may not lead to more bookings.\nInstant Bookable (0.19): Listings that are instantly bookable tend to have more bookings than those that are not. This suggests that ease of booking is an important factor for customers when choosing properties.\nRoom Type: Private Room (-0.05): Listings with private rooms have fewer bookings compared to the reference category (entire home/apt). This suggests private rooms may be less attractive to a larger customer base.\nRoom Type: Shared Room (-0.04): Listings with shared rooms also have fewer bookings than the reference category. This indicates that shared rooms appeal to a niche market, leading to fewer bookings.\n\n\nConclusion\nThe most important factors influencing the number of bookings (as proxied by reviews) for Airbnb listings in New York City include the number of days since the listing was created, and whether the listing is instantly bookable. These factors have the largest impact on bookings, with older listings and instantly bookable listings attracting more bookings. Other factors such as the number of bedrooms and bathrooms, price, and room type had a relatively smaller impact on bookings.There were some unexpected results, such as the negative coefficients for location and value review scores, which may require further investigation.\nThe model provides insights into the factors that drive bookings and can help hosts optimize their listings for better performance."
  }
]